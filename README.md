# C3RAG

This repository contains:
1. LLM-as-a-Judge prompts based on the paper [*Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena*](https://arxiv.org/abs/2306.05685), specifically the single-answer grading variation;
2. LLM-as-a-Judge evaluation results:
      [Human's Answer] refers to handcrafted ground-truth statements synthesized from case-critical information for each clause.
      [AI's Answer] represents the analysis results automatically generated by C3RAG under different combinations (OS, OD, CS, and CD).

The remaining data will be released after the related workâ€™s publication.
