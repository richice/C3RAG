# C3RAG

This repository contains:
1. prompts based on the paper *Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena*, specifically the single-answer grading variation;
2. LLM-as-a-Judge evaluation results:
      [Human's Answer] refers to handcrafted ground-truth statements synthesized from case-critical information for each clause.
      [AI's Answer] represents the analysis results automatically generated by C3RAG under different combinations (OS, OD, CS, and CD).

The remaining data will be released after the related workâ€™s publication.
